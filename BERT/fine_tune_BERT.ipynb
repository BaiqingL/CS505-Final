{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2c9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb516223",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c261c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab6afdb",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bd901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/2017_English_final/GOLD/Subtask_A/'\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file_name in files:\n",
    "        if 'train' in file_name and '.txt' in file_name:\n",
    "            train_files.append(os.path.join(data_dir, file_name))\n",
    "        if 'dev' in file_name and '.txt' in file_name:\n",
    "            val_files.append(os.path.join(data_dir, file_name))\n",
    "        if 'test' in file_name and '.txt' in file_name:\n",
    "            test_files.append(os.path.join(data_dir, file_name))\n",
    "        \n",
    "train_data = []\n",
    "train_labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "for file_path in train_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            train_data.append(entries[2])\n",
    "            train_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "for file_path in val_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            val_data.append(entries[2])\n",
    "            val_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f965c",
   "metadata": {},
   "source": [
    "### Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "328a5196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d568a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  116\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for tweet in np.concatenate((train_data, val_data)):\n",
    "    \n",
    "    if len(tweet) > 280:\n",
    "        print('The following entry is longer than the max tweet length:')\n",
    "        print(tweet)\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(tweet, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bca3184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr4/cs440/richchen/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1,  ..., 1, 2, 1])\n",
      "tensor([1, 1, 0,  ..., 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "\n",
    "def tokenize_data(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    # For every sentence...\n",
    "    for tweet in data:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            tweet,                      # Tweet to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_len+100,  # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    print(labels)\n",
    "    \n",
    "    return input_ids, attention_masks, labels \n",
    "\n",
    "\n",
    "input_ids_train, attention_masks_train, labels_train = tokenize_data(train_data, train_labels)\n",
    "input_ids_val, attention_masks_val, labels_val = tokenize_data(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e37ed6",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643fa290",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb315ee",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ca584d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 3, # The number of output labels--3 for 3 classes.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a908b024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/cs440/richchen/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac896cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5af053",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cd8a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70c129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694ec66",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ce4348c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:14.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:28.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:43.\n",
      "  Batch   160  of    506.    Elapsed: 0:00:57.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:26.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:40.\n",
      "  Batch   320  of    506.    Elapsed: 0:01:55.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:09.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:24.\n",
      "  Batch   440  of    506.    Elapsed: 0:02:38.\n",
      "  Batch   480  of    506.    Elapsed: 0:02:52.\n",
      "\n",
      "  Average training loss: 0.72\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 0.81\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:44.\n",
      "  Batch   160  of    506.    Elapsed: 0:00:58.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:13.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:27.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:42.\n",
      "  Batch   320  of    506.    Elapsed: 0:01:56.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:10.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:25.\n",
      "  Batch   440  of    506.    Elapsed: 0:02:39.\n",
      "  Batch   480  of    506.    Elapsed: 0:02:54.\n",
      "\n",
      "  Average training loss: 0.49\n",
      "  Training epcoh took: 0:03:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.64\n",
      "  Validation Loss: 0.80\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:14.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:43.\n",
      "  Batch   160  of    506.    Elapsed: 0:00:57.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:26.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:40.\n",
      "  Batch   320  of    506.    Elapsed: 0:01:55.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:09.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:23.\n",
      "  Batch   440  of    506.    Elapsed: 0:02:38.\n",
      "  Batch   480  of    506.    Elapsed: 0:02:52.\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:03:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 0.90\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:29.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:43.\n",
      "  Batch   160  of    506.    Elapsed: 0:00:58.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:12.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:26.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:41.\n",
      "  Batch   320  of    506.    Elapsed: 0:01:55.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:09.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:24.\n",
      "  Batch   440  of    506.    Elapsed: 0:02:38.\n",
      "  Batch   480  of    506.    Elapsed: 0:02:52.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epcoh took: 0:03:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.65\n",
      "  Validation Loss: 1.03\n",
      "  Validation took: 0:00:21\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:13:30 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f6b1a",
   "metadata": {},
   "source": [
    "### Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85613d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0:03:01</td>\n",
       "      <td>0:00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0:03:03</td>\n",
       "      <td>0:00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:03:01</td>\n",
       "      <td>0:00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.24</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0:03:02</td>\n",
       "      <td>0:00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.72         0.81           0.61       0:03:01         0:00:21\n",
       "2               0.49         0.80           0.64       0:03:03         0:00:21\n",
       "3               0.34         0.90           0.65       0:03:01         0:00:21\n",
       "4               0.24         1.03           0.65       0:03:02         0:00:21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d4fdae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d6cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_dir = '/projectnb2/cs542sb/students/richchen/CS505-Final/BERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b763e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(scc_dir + '/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd96caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(scc_dir + '/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63adf0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75511a27",
   "metadata": {},
   "source": [
    "### Prepare Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ed87cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = '../data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.english.txt'\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        entries = l.split('\\t')\n",
    "        if len(entries) != 3:\n",
    "            entries = l.split(' ', maxsplit=2)\n",
    "        test_data.append(entries[2])\n",
    "        test_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb7950bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids_test, attention_masks_test, labels_test = tokenize_data(test_data, test_labels)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00fd6882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,355 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "  logits = result.logits\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d374b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6157973174366617\n"
     ]
    }
   ],
   "source": [
    "predictions = [p for sublist in predictions for p in sublist]\n",
    "true_labels = np.array([l for sublist in true_labels for l in sublist])\n",
    "print(flat_accuracy(predictions, true_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
