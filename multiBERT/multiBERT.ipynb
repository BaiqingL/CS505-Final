{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b863cb-92ca-4803-90ef-28efd9033e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443a7bff-c991-40dd-b48c-ccc7abb64bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8097c-32ab-45da-bf37-b6ce99d204b3",
   "metadata": {},
   "source": [
    "Task at hand: **multilingual model trained on English tweets and test on Arabic tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e5e82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/2017_English_final/GOLD/Subtask_A/'\n",
    "\n",
    "train_files = []\n",
    "val_files = []\n",
    "test_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file_name in files:\n",
    "        if 'train' in file_name and '.txt' in file_name:\n",
    "            train_files.append(os.path.join(data_dir, file_name))\n",
    "        if 'dev' in file_name and '.txt' in file_name:\n",
    "            val_files.append(os.path.join(data_dir, file_name))\n",
    "        if 'test' in file_name and '.txt' in file_name:\n",
    "            test_files.append(os.path.join(data_dir, file_name))\n",
    "        \n",
    "train_data = []\n",
    "train_labels = []\n",
    "val_data = []\n",
    "val_labels = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "for file_path in train_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            train_data.append(entries[2])\n",
    "            train_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "for file_path in val_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            val_data.append(entries[2])\n",
    "            val_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "val_data = np.array(val_data)\n",
    "val_labels = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceed20e2-8252-4c14-91ea-af3f2815ed85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88342cd4-5a97-448f-b8c4-3db1a6f86f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  142\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for tweet in np.concatenate((train_data, val_data)):\n",
    "    \n",
    "    if len(tweet) > 280:\n",
    "        print('The following entry is longer than the max tweet length:')\n",
    "        print(tweet)\n",
    "    \n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(tweet, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c38c185e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr4/cs542sp/baiqing/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1,  ..., 1, 2, 1])\n",
      "tensor([1, 1, 0,  ..., 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "\n",
    "def tokenize_data(data, labels):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    # For every sentence...\n",
    "    for tweet in data:\n",
    "        # `encode_plus` will:\n",
    "        #   (1) Tokenize the sentence.\n",
    "        #   (2) Prepend the `[CLS]` token to the start.\n",
    "        #   (3) Append the `[SEP]` token to the end.\n",
    "        #   (4) Map tokens to their IDs.\n",
    "        #   (5) Pad or truncate the sentence to `max_length`\n",
    "        #   (6) Create attention masks for [PAD] tokens.\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            tweet,                      # Tweet to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = max_len+100,  # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "\n",
    "        # Add the encoded sentence to the list.    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "        # And its attention mask (simply differentiates padding from non-padding).\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    # Convert the lists into tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    labels = torch.tensor(labels)\n",
    "    print(labels)\n",
    "    \n",
    "    return input_ids, attention_masks, labels \n",
    "\n",
    "\n",
    "input_ids_train, attention_masks_train, labels_train = tokenize_data(train_data, train_labels)\n",
    "input_ids_val, attention_masks_val, labels_val = tokenize_data(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c67653c2-9b5a-4b20-be5f-6f8c3a927296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a42e3f4-40ad-4e8e-8067-d937b4fab94e",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0144aa2-b869-4bc5-94b9-3ea080803fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19e5815-9e4b-450b-bf3e-e313132c3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42170f5f-1352-4499-b032-cee36a45bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63bfde5-6008-4cd8-bbc8-4c790a64ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5e35137-554f-47f9-95fe-8d8be4afbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e2455-fc49-4715-94b3-1cf8673c8f15",
   "metadata": {},
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10dbc73e-e891-4764-ba9c-df8f489f323b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:33.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:50.\n",
      "  Batch   160  of    506.    Elapsed: 0:01:07.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:24.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:41.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:58.\n",
      "  Batch   320  of    506.    Elapsed: 0:02:14.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:31.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:48.\n",
      "  Batch   440  of    506.    Elapsed: 0:03:05.\n",
      "  Batch   480  of    506.    Elapsed: 0:03:22.\n",
      "\n",
      "  Average training loss: 0.79\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.55\n",
      "  Validation Loss: 0.93\n",
      "  Validation took: 0:00:24\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:50.\n",
      "  Batch   160  of    506.    Elapsed: 0:01:07.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:24.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:40.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:57.\n",
      "  Batch   320  of    506.    Elapsed: 0:02:14.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:31.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:47.\n",
      "  Batch   440  of    506.    Elapsed: 0:03:04.\n",
      "  Batch   480  of    506.    Elapsed: 0:03:21.\n",
      "\n",
      "  Average training loss: 0.60\n",
      "  Training epcoh took: 0:03:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.60\n",
      "  Validation Loss: 0.86\n",
      "  Validation took: 0:00:24\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:33.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:50.\n",
      "  Batch   160  of    506.    Elapsed: 0:01:07.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:24.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:40.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:57.\n",
      "  Batch   320  of    506.    Elapsed: 0:02:14.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:31.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:47.\n",
      "  Batch   440  of    506.    Elapsed: 0:03:04.\n",
      "  Batch   480  of    506.    Elapsed: 0:03:21.\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 0.94\n",
      "  Validation took: 0:00:24\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    506.    Elapsed: 0:00:17.\n",
      "  Batch    80  of    506.    Elapsed: 0:00:34.\n",
      "  Batch   120  of    506.    Elapsed: 0:00:50.\n",
      "  Batch   160  of    506.    Elapsed: 0:01:07.\n",
      "  Batch   200  of    506.    Elapsed: 0:01:24.\n",
      "  Batch   240  of    506.    Elapsed: 0:01:40.\n",
      "  Batch   280  of    506.    Elapsed: 0:01:57.\n",
      "  Batch   320  of    506.    Elapsed: 0:02:14.\n",
      "  Batch   360  of    506.    Elapsed: 0:02:31.\n",
      "  Batch   400  of    506.    Elapsed: 0:02:47.\n",
      "  Batch   440  of    506.    Elapsed: 0:03:04.\n",
      "  Batch   480  of    506.    Elapsed: 0:03:21.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:03:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation Loss: 1.02\n",
      "  Validation took: 0:00:24\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:15:43 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1672e02-7402-4dbe-aa9f-d5c323b390ef",
   "metadata": {},
   "source": [
    "#### Training summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "050a9a03-b1e1-42fa-b47e-00d462740114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791499</td>\n",
       "      <td>0.926867</td>\n",
       "      <td>0.547972</td>\n",
       "      <td>0:03:32</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596788</td>\n",
       "      <td>0.855694</td>\n",
       "      <td>0.601308</td>\n",
       "      <td>0:03:32</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.463669</td>\n",
       "      <td>0.941638</td>\n",
       "      <td>0.612608</td>\n",
       "      <td>0:03:31</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.356798</td>\n",
       "      <td>1.017495</td>\n",
       "      <td>0.611985</td>\n",
       "      <td>0:03:31</td>\n",
       "      <td>0:00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1           0.791499     0.926867       0.547972       0:03:32         0:00:24\n",
       "2           0.596788     0.855694       0.601308       0:03:32         0:00:24\n",
       "3           0.463669     0.941638       0.612608       0:03:31         0:00:24\n",
       "4           0.356798     1.017495       0.611985       0:03:31         0:00:24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "838d1119-857b-46d7-9ec1-7ddd46d64435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d112f06-d44b-43da-95e9-d5468e5e1f77",
   "metadata": {},
   "source": [
    "#### Load zero shot classification on Arabic tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50044bcb-d6fc-4c13-ba3c-cfbf82cad242",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/2017_Arabic_train_final\"\n",
    "text_files = [os.path.join(dp, f) for dp, dn, filenames in os.walk(PATH) for f in filenames if os.path.splitext(f)[1] == '.txt']\n",
    "test_files = []\n",
    "for file_path in text_files:\n",
    "    if \"arabic\" in file_path and \"GOLD\" in file_path and \"subtask-A\" in file_path and \".ipynb\" not in file_path:\n",
    "        test_files.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74ee141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_file_path = '../data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.arabic.txt'\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        entries = l.split('\\t')\n",
    "        if len(entries) != 3:\n",
    "            entries = l.split(' ', maxsplit=2)\n",
    "        test_data.append(entries[2])\n",
    "        test_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61d6d3c6-8e67-40b8-b874-667ec0ca4c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2,  ..., 1, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr4/cs542sp/baiqing/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids_test, attention_masks_test, labels_test = tokenize_data(test_data, test_labels)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2eb5a9f-081d-4e66-aac8-69987c41e851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,355 test sentences...\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e03c9038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5081967213114754\n"
     ]
    }
   ],
   "source": [
    "predictions = [p for sublist in predictions for p in sublist]\n",
    "true_labels = np.array([l for sublist in true_labels for l in sublist])\n",
    "print(flat_accuracy(predictions, true_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd8845-fb88-47f6-be72-58740cbb5842",
   "metadata": {},
   "source": [
    "#### Also test on translated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fbc65a7-4195-4b76-b9af-7a055655d8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.english.txt']\n"
     ]
    }
   ],
   "source": [
    "test_file_path = '../data/2017_Arabic_train_final/GOLD/'\n",
    "\n",
    "test_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(test_file_path):\n",
    "    for file_name in files:\n",
    "        if 'english' in file_name and 'subtask-A' in file_name and '.txt' in file_name:\n",
    "            test_files.append(os.path.join(test_file_path, file_name))\n",
    "\n",
    "print(test_files)\n",
    "            \n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "for file_path in test_files:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            if len(entries) != 3:\n",
    "                entries = l.split(' ', maxsplit=2)\n",
    "            test_data.append(entries[2])\n",
    "            test_labels.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41731d7d-6f54-4abc-b18a-56b1a3867937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input_ids_test, attention_masks_test, labels_test = tokenize_data(test_data, test_labels)\n",
    "\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77f2c66a-f8c4-4c64-899c-9a510d6c9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 3,355 test sentences...\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions.\n",
    "      result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff66facb-7bd9-4863-bcc4-52a783ac1282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.580327868852459\n"
     ]
    }
   ],
   "source": [
    "predictions = [p for sublist in predictions for p in sublist]\n",
    "true_labels = np.array([l for sublist in true_labels for l in sublist])\n",
    "print(flat_accuracy(predictions, true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73826f5-0e49-41bc-be00-92f1669dbbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
