{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u8xBtDGlxvz4",
    "outputId": "fbffd73a-fff9-43cb-ffbd-615f15c16c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May  5 07:17:44 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:18:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    45W / 300W |      0MiB / 16160MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    44W / 300W |      0MiB / 16160MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    45W / 300W |      0MiB / 16160MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:AF:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    44W / 300W |      0MiB / 16160MiB |      0%   E. Process |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbpX3_9PxzVE",
    "outputId": "143c6627-5f94-44a1-dd2e-9b3d32b0d350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (4.17.0)\n",
      "Collecting SentencePiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 8.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (1.9.0)\n",
      "Requirement already satisfied: tqdm in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (4.51.0)\n",
      "Requirement already satisfied: filelock in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages/numpy-1.19.4-py3.8-linux-x86_64.egg (from transformers) (1.19.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (2020.10.28)\n",
      "Requirement already satisfied: sacremoses in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: requests in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr4/cs523/tengzi/.local/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: typing-extensions in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: click in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: six in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Installing collected packages: SentencePiece\n",
      "Successfully installed SentencePiece-0.1.96\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers SentencePiece torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sqiBMWGHx3Yx"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import MT5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "w9dorhOHyydQ"
   },
   "outputs": [],
   "source": [
    "class SoftEmbedding(nn.Module):\n",
    "    def __init__(self, \n",
    "                wte: nn.Embedding,\n",
    "                n_tokens: int = 10, \n",
    "                random_range: float = 0.5,\n",
    "                initialize_from_vocab: bool = True):\n",
    "        \"\"\"appends learned embedding to \n",
    "        Args:\n",
    "            wte (nn.Embedding): original transformer word embedding\n",
    "            n_tokens (int, optional): number of tokens for task. Defaults to 10.\n",
    "            random_range (float, optional): range to init embedding (if not initialize from vocab). Defaults to 0.5.\n",
    "            initialize_from_vocab (bool, optional): initalizes from default vocab. Defaults to True.\n",
    "        \"\"\"\n",
    "        super(SoftEmbedding, self).__init__()\n",
    "        self.wte = wte\n",
    "        self.n_tokens = n_tokens\n",
    "        self.learned_embedding = nn.parameter.Parameter(self.initialize_embedding(wte,\n",
    "                                                                                  n_tokens, \n",
    "                                                                                  random_range, \n",
    "                                                                                  initialize_from_vocab))\n",
    "            \n",
    "    def initialize_embedding(self, \n",
    "                             wte: nn.Embedding,\n",
    "                             n_tokens: int = 10, \n",
    "                             random_range: float = 0.5, \n",
    "                             initialize_from_vocab: bool = True):\n",
    "        \"\"\"initializes learned embedding\n",
    "        Args:\n",
    "            same as __init__\n",
    "        Returns:\n",
    "            torch.float: initialized using original schemes\n",
    "        \"\"\"\n",
    "        if initialize_from_vocab:\n",
    "            return self.wte.weight[:n_tokens].clone().detach()\n",
    "        return torch.FloatTensor(n_tokens, wte.weight.size(1)).uniform_(-random_range, random_range)\n",
    "            \n",
    "    def forward(self, tokens):\n",
    "        \"\"\"run forward pass\n",
    "        Args:\n",
    "            tokens (torch.long): input tokens before encoding\n",
    "        Returns:\n",
    "            torch.float: encoding of text concatenated with learned task specifc embedding\n",
    "        \"\"\"\n",
    "        input_embedding = self.wte(tokens[:, self.n_tokens:])\n",
    "        learned_embedding = self.learned_embedding.repeat(input_embedding.size(0), 1, 1)\n",
    "        return torch.cat([learned_embedding, input_embedding], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "We6vNt5ukkBJ"
   },
   "outputs": [],
   "source": [
    "# !pip install zh-dataset-inews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "biQD2_aB6v8s"
   },
   "outputs": [],
   "source": [
    "# from zh_dataset_inews import title_train, label_train, title_dev, label_dev, title_test, label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-e1LGFszVtz",
    "outputId": "8550b3c0-9f2f-4b35-b9de-9661fa06c963"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path='drive/MyDrive/CS505/CS505-Final/'\n",
    "path=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8xhJDF6zgwB",
    "outputId": "7c82bb55-0d52-467f-efeb-3cd999f47efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/2017_English_final/GOLD/Subtask_A/twitter-2015train-A.txt', 'data/2017_English_final/GOLD/Subtask_A/twitter-2013train-A.txt', 'data/2017_English_final/GOLD/Subtask_A/twitter-2016train-A.txt']\n",
      "['data/2017_English_final/GOLD/Subtask_A/twitter-2016devtest-A.txt', 'data/2017_English_final/GOLD/Subtask_A/twitter-2013dev-A.txt', 'data/2017_English_final/GOLD/Subtask_A/twitter-2016dev-A.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "eng_path=path+'data/2017_English_final/GOLD/Subtask_A/'\n",
    "train_file=[]\n",
    "val_file=[]\n",
    "\n",
    "for root, dirs, files in os.walk(eng_path):\n",
    "    for file_name in files:\n",
    "        if 'train' in file_name and '.txt' in file_name:\n",
    "            train_file.append(os.path.join(eng_path, file_name))\n",
    "        if 'dev' in file_name and '.txt' in file_name:\n",
    "            val_file.append(os.path.join(eng_path, file_name))\n",
    "print(train_file)\n",
    "print(val_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ggh84mtVzmyl"
   },
   "outputs": [],
   "source": [
    "title_train = []\n",
    "label_train = []\n",
    "title_dev = []\n",
    "label_dev = []\n",
    "\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "for file_path in train_file:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            title_train.append(entries[2])\n",
    "            label_train.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "    \n",
    "for file_path in val_file:\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for l in lines:\n",
    "            entries = l.split('\\t')\n",
    "            title_dev.append(entries[2])\n",
    "            label_dev.append(sentiment_to_label[entries[1]])\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Vn1iVWZs0Z4Z"
   },
   "outputs": [],
   "source": [
    "arabic_path=path+'data/2017_Arabic_train_final/GOLD/SemEval2017-task4-train.subtask-A.arabic.txt'\n",
    "\n",
    "title_test = []\n",
    "label_test = []\n",
    "\n",
    "sentiment_to_label = {'positive': 2, 'neutral': 1, 'negative': 0}\n",
    "\n",
    "with open(arabic_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for l in lines:\n",
    "        entries = l.split('\\t')\n",
    "        title_test.append(entries[2])\n",
    "        label_test.append(sentiment_to_label[entries[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LfF_Z4qu0z3a"
   },
   "outputs": [],
   "source": [
    "def generate_data(batch_size, n_tokens, title_data, label_data):\n",
    "\n",
    "    labels = [\n",
    "        torch.tensor([[3]]),  # \\x00\n",
    "        torch.tensor([[4]]),  # \\x01\n",
    "        torch.tensor([[5]]),  # \\x02\n",
    "    ]\n",
    "\n",
    "    def yield_data(x_batch, y_batch, l_batch):\n",
    "        x = torch.nn.utils.rnn.pad_sequence(x_batch, batch_first=True)\n",
    "        y = torch.cat(y_batch, dim=0)\n",
    "        m = (x > 0).to(torch.float32)\n",
    "        decoder_input_ids = torch.full((x.size(0), n_tokens), 1)\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            m = m.cuda()\n",
    "            decoder_input_ids = decoder_input_ids.cuda()\n",
    "        return x, y, m, decoder_input_ids, l_batch\n",
    "\n",
    "    x_batch, y_batch, l_batch = [], [], []\n",
    "    for x, y in zip(title_data, label_data):\n",
    "        context = x\n",
    "        inputs = tokenizer(context, return_tensors=\"pt\")\n",
    "        inputs['input_ids'] = torch.cat([torch.full((1, n_tokens), 1), inputs['input_ids']], 1)\n",
    "        l_batch.append(y)\n",
    "        y = labels[y]\n",
    "        y = torch.cat([torch.full((1, n_tokens - 1), -100), y], 1)\n",
    "        x_batch.append(inputs['input_ids'][0])\n",
    "        y_batch.append(y)\n",
    "        if len(x_batch) >= batch_size:\n",
    "            yield yield_data(x_batch, y_batch, l_batch)\n",
    "            x_batch, y_batch, l_batch = [], [], []\n",
    "\n",
    "    if len(x_batch) > 0:\n",
    "        yield yield_data(x_batch, y_batch, l_batch)\n",
    "        x_batch, y_batch, l_batch = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5NKTnNidXnzS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df436ac0d9ea495b94db23f7aefe406c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=4309802.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d41e434b7c412688d45c87c873d515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=65.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c889ed1da15a4b5baf887e6d4d01ff50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=376.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/mt5-base\")\n",
    "n_tokens = 512\n",
    "s_wte = SoftEmbedding(model.get_input_embeddings(), \n",
    "                      n_tokens=n_tokens, \n",
    "                      initialize_from_vocab=True)\n",
    "model.set_input_embeddings(s_wte)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "eaKnkA8M4Am4"
   },
   "outputs": [],
   "source": [
    "parameters = list(model.parameters())\n",
    "for x in parameters[1:]:\n",
    "    x.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YR1cPDym4LYi",
    "outputId": "4a980e9d-4c23-46c0-c5a7-18f3d6961f29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.7500e+00, -1.6719e+00,  2.4062e+00,  ...,  6.9580e-03,\n",
       "         -9.8828e-01, -4.6875e-01],\n",
       "        [ 8.5625e+00,  5.5625e+00, -1.7109e+00,  ...,  7.7812e+00,\n",
       "         -5.2812e+00, -3.2188e+00],\n",
       "        [ 6.8750e-01, -4.5312e-01,  5.7812e-01,  ...,  7.3828e-01,\n",
       "         -3.0078e-01,  2.0312e-01],\n",
       "        ...,\n",
       "        [-3.1250e+00, -7.0938e+00,  2.7812e+00,  ..., -1.0688e+01,\n",
       "          4.5312e+00, -3.0156e+00],\n",
       "        [-7.0625e+00, -7.4688e+00,  1.3875e+01,  ..., -4.9062e+00,\n",
       "         -4.5625e+00,  7.4375e+00],\n",
       "        [-1.0400e-01,  9.0000e+00,  3.3281e+00,  ...,  6.1250e+00,\n",
       "          1.0750e+01, -1.0107e-01]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b20PaXQA4L4n",
    "outputId": "dd9fbc0e-1ed8-48fe-de56-1abddab484e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.3977e-02,  3.8818e-02,  5.7129e-02,  ...,  4.9316e-02,\n",
       "         -8.1177e-03, -3.8147e-03],\n",
       "        [ 6.3965e-02, -1.0193e-02, -2.0020e-02,  ..., -8.3618e-03,\n",
       "         -1.1902e-02, -2.6978e-02],\n",
       "        [-1.6357e-02, -4.4922e-02,  4.8584e-02,  ..., -1.6479e-02,\n",
       "         -4.0039e-02,  6.3782e-03],\n",
       "        ...,\n",
       "        [ 7.7820e-03, -6.5918e-03, -3.9062e-03,  ...,  1.9165e-02,\n",
       "          7.4863e-05, -2.6001e-02],\n",
       "        [-1.4587e-02,  1.8433e-02, -2.6489e-02,  ..., -3.9062e-02,\n",
       "         -4.0527e-02,  4.1992e-02],\n",
       "        [ 7.8125e-02,  1.6602e-02,  6.4941e-02,  ...,  4.2152e-04,\n",
       "          4.5166e-02, -1.1780e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "uXKtiZOPkKwZ"
   },
   "outputs": [],
   "source": [
    "for x, y, m, dii, true_labels in generate_data(2, n_tokens, title_train, label_train):\n",
    "    assert dii.shape == y.shape\n",
    "    outputs = model(input_ids=x, labels=y, attention_mask=m, decoder_input_ids=dii)\n",
    "    assert outputs['logits'].shape[:2] == y.shape\n",
    "    pred_labels = outputs['logits'][:, -1, 3:6].argmax(-1).detach().cpu().numpy().tolist()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdZ3dTfK3-ob",
    "outputId": "f3f85b9e-4178-4c04-a68b-465c5b152160"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/8087 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: loss=2.8273, acc=0.3930: 100%|██████████| 8087/8087 [30:12<00:00,  4.46it/s] \n",
      "dev: loss=0.6558, acc=0.4267: 100%|██████████| 2827/2827 [05:03<00:00,  9.33it/s]\n",
      "  0%|          | 0/8087 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: loss=2.6818, acc=0.4103: 100%|██████████| 8087/8087 [30:09<00:00,  4.47it/s]\n",
      "dev: loss=1.2859, acc=0.4265: 100%|██████████| 2827/2827 [05:04<00:00,  9.29it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size =2\n",
    "n_epoch = 2\n",
    "total_batch = math.ceil(len(title_train) / batch_size)\n",
    "dev_total_batch = math.ceil(len(title_dev) / batch_size)\n",
    "use_ce_loss = False\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(s_wte.parameters(), lr=0.5)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    print('epoch', epoch)\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    losses = []\n",
    "    pbar = tqdm(enumerate(generate_data(batch_size, n_tokens, title_train, label_train)), total=total_batch)\n",
    "    for i, (x, y, m, dii, true_labels) in pbar:\n",
    "        all_true_labels += true_labels\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=x, labels=y, attention_mask=m, decoder_input_ids=dii)\n",
    "        pred_labels = outputs['logits'][:, -1, 3:6].argmax(-1).detach().cpu().numpy().tolist()\n",
    "        all_pred_labels += pred_labels\n",
    "\n",
    "        if use_ce_loss:\n",
    "            logits = outputs['logits'][:, -1, 3:6]\n",
    "            true_labels_tensor = torch.tensor(true_labels, dtype=torch.long).cuda()\n",
    "            loss = ce_loss(logits, true_labels_tensor)\n",
    "        else:\n",
    "            loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = float(loss.detach().cpu().numpy().tolist()) / batch_size\n",
    "        losses.append(loss_value)\n",
    "\n",
    "        acc = accuracy_score(all_true_labels, all_pred_labels)\n",
    "        pbar.set_description(f'train: loss={np.mean(losses):.4f}, acc={acc:.4f}')\n",
    "\n",
    "    all_true_labels = []\n",
    "    all_pred_labels = []\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(enumerate(generate_data(batch_size, n_tokens, title_dev, label_dev)), total=dev_total_batch)\n",
    "        for i, (x, y, m, dii, true_labels) in pbar:\n",
    "            all_true_labels += true_labels\n",
    "            outputs = model(input_ids=x, labels=y, attention_mask=m, decoder_input_ids=dii)\n",
    "            loss = outputs.loss\n",
    "            loss_value = float(loss.detach().cpu().numpy().tolist()) / batch_size\n",
    "            losses.append(loss_value)\n",
    "            pred_labels = outputs['logits'][:, -1, 3:6].argmax(-1).detach().cpu().numpy().tolist()\n",
    "            all_pred_labels += pred_labels\n",
    "            acc = accuracy_score(all_true_labels, all_pred_labels)\n",
    "            pbar.set_description(f'dev: loss={np.mean(losses):.4f}, acc={acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Zrxp8Im04beQ"
   },
   "outputs": [],
   "source": [
    "parameters2 = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRBcvIbY4s-R",
    "outputId": "9dcdf464-500b-4b39-da73-7105759f44b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 28.8612, -22.3175, -50.1415,  ...,  -6.7055,   1.7269,  24.0909],\n",
       "        [ 29.1193,  12.5699,  -8.7134,  ..., -23.2332,  -9.5085, -10.3435],\n",
       "        [-29.0432,  30.6009, -16.5832,  ...,   2.1478,  15.7382,   2.1589],\n",
       "        ...,\n",
       "        [ 36.9844,  -1.8403,  11.0625,  ..., -44.9269,   5.5143,  22.6365],\n",
       "        [-34.8258, -42.9783,  -4.9431,  ...,  23.6431,  25.1618,  60.8522],\n",
       "        [ 50.4875, -21.9642, -32.0669,  ...,  -0.5277,  -6.1080,   0.5091]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mp_0DmKr4tZA",
    "outputId": "61bddd2a-5709-4fe7-b2f3-b072feed405b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.3977e-02,  3.8818e-02,  5.7129e-02,  ...,  4.9316e-02,\n",
       "         -8.1177e-03, -3.8147e-03],\n",
       "        [ 6.3965e-02, -1.0193e-02, -2.0020e-02,  ..., -8.3618e-03,\n",
       "         -1.1902e-02, -2.6978e-02],\n",
       "        [-1.6357e-02, -4.4922e-02,  4.8584e-02,  ..., -1.6479e-02,\n",
       "         -4.0039e-02,  6.3782e-03],\n",
       "        ...,\n",
       "        [ 7.7820e-03, -6.5918e-03, -3.9062e-03,  ...,  1.9165e-02,\n",
       "          7.4863e-05, -2.6001e-02],\n",
       "        [-1.4587e-02,  1.8433e-02, -2.6489e-02,  ..., -3.9062e-02,\n",
       "         -4.0527e-02,  4.1992e-02],\n",
       "        [ 7.8125e-02,  1.6602e-02,  6.4941e-02,  ...,  4.2152e-04,\n",
       "          4.5166e-02, -1.1780e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Oqdi4A7tFnxM"
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    inputs['input_ids'] = torch.cat([torch.full((1, n_tokens), 1), inputs['input_ids']], 1)\n",
    "\n",
    "    decoder_input_ids = torch.full((1, n_tokens), 1)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=inputs['input_ids'].cuda(), decoder_input_ids=decoder_input_ids.cuda())\n",
    "    logits = outputs['logits'][:, -1, 3:6]\n",
    "    pred = logits.argmax(-1).detach().cpu().numpy()[0]\n",
    "    # print(logits)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "ohlT29oGueUD",
    "outputId": "fdcc7ec6-60bb-4a4f-aae4-c0f39af8ff7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16173/16173 [14:32<00:00, 18.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# train_rets = []\n",
    "# for i in tqdm(range(len(title_train))):\n",
    "#     pred = predict(title_train[i])\n",
    "#     train_rets.append((label_train[i], pred, title_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "NE84AeC9BC8U"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3355/3355 [03:02<00:00, 18.38it/s]\n"
     ]
    }
   ],
   "source": [
    "rets = []\n",
    "for i in tqdm(range(len(title_test))):\n",
    "    pred = predict(title_test[i])\n",
    "    rets.append((label_test[i], pred, title_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "DZOnkUtKuiwa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4254621900698695\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(\n",
    "        [x[0] for x in train_rets],\n",
    "        [x[1] for x in train_rets],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "74CWYzXXuW-W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2360655737704918\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(\n",
    "        [x[0] for x in rets],\n",
    "        [x[1] for x in rets],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "D8vIKsvAuCpX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34038748137108793 0.43815201192250375 0.22146050670640835\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    accuracy_score(\n",
    "        [x[0] for x in rets],\n",
    "        [0] * len(rets),\n",
    "    ),\n",
    "    accuracy_score(\n",
    "        [x[0] for x in rets],\n",
    "        [1] * len(rets),\n",
    "    ),\n",
    "    accuracy_score(\n",
    "        [x[0] for x in rets],\n",
    "        [2] * len(rets),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "1O1uwg8irIdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum([1 for x in rets if x[1]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of mt5-soft-prompt-tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
